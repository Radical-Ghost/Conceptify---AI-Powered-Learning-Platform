{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "87a2db92",
   "metadata": {},
   "source": [
    "# OCR Test with Tesseract\n",
    "\n",
    "## Requirements\n",
    "1. **Install Tesseract OCR**: \n",
    "   - Install Tesseract: `winget install --id UB-Mannheim.TesseractOCR` \n",
    "   - add it to system varibales \n",
    "2. **Python packages**: `pip install opencv-python pytesseract pillow`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "38e6c8df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully loaded image: ./Tests files/test_image_only.png\n",
      "Image shape: (206, 1067, 3)\n",
      "Extracted text:\n",
      "Experiment-07\n",
      "\n",
      "Roll No: A3-754\n",
      "\n",
      "Aim: To study & implement Part-of-Speech (POS) tagging using the Viterbi Algorithm in Hidden Markov\n",
      "Models (HMM)\n",
      "\n",
      "Text saved to 'Tests output\\output_from_image.txt'\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import pytesseract\n",
    "from PIL import Image\n",
    "import os\n",
    "\n",
    "# Load image - corrected file extension\n",
    "image_path = \"./Tests files/test_image_only.png\"\n",
    "\n",
    "# Check if file exists\n",
    "if not os.path.exists(image_path):\n",
    "    print(f\"Error: File '{image_path}' not found!\")\n",
    "    print(\"Available files in Tests files directory:\")\n",
    "    for file in os.listdir(\"./Tests files\"):\n",
    "        print(f\"  - {file}\")\n",
    "else:\n",
    "    img = cv2.imread(image_path)\n",
    "    \n",
    "    # Check if image was loaded successfully\n",
    "    if img is None:\n",
    "        print(f\"Error: Could not load image from '{image_path}'\")\n",
    "        print(\"Make sure the file is a valid image format.\")\n",
    "    else:\n",
    "        print(f\"Successfully loaded image: {image_path}\")\n",
    "        print(f\"Image shape: {img.shape}\")\n",
    "        \n",
    "        # Convert to grayscale\n",
    "        gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "        \n",
    "        # Optional preprocessing\n",
    "        gray = cv2.GaussianBlur(gray, (5,5), 0)\n",
    "        gray = cv2.adaptiveThreshold(gray, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C,\n",
    "                                     cv2.THRESH_BINARY, 11, 2)\n",
    "\n",
    "        # OCR with error handling\n",
    "        try:\n",
    "            text = pytesseract.image_to_string(gray)\n",
    "            print(\"Extracted text:\")\n",
    "            print(text)\n",
    "\n",
    "            # Create output directory if it doesn't exist\n",
    "            output_dir = \"Tests output\"\n",
    "            if not os.path.exists(output_dir):\n",
    "                os.makedirs(output_dir)\n",
    "                print(f\"Created directory: {output_dir}\")\n",
    "\n",
    "            # Save to file\n",
    "            output_file = os.path.join(output_dir, \"output_from_image.txt\")\n",
    "            with open(output_file, \"w\", encoding=\"utf-8\") as f:\n",
    "                f.write(text)\n",
    "            print(f\"Text saved to '{output_file}'\")\n",
    "            \n",
    "        except pytesseract.TesseractNotFoundError:\n",
    "            print(\"ERROR: Tesseract is not installed or not in PATH!\")\n",
    "            print(\"\\nTo install Tesseract:\")\n",
    "            print(\"1. Download from: https://github.com/UB-Mannheim/tesseract/wiki\")\n",
    "            print(\"2. Or use chocolatey: choco install tesseract\")\n",
    "            print(\"3. Or use conda: conda install -c conda-forge tesseract\")\n",
    "            print(\"4. Make sure to add Tesseract to your system PATH\")\n",
    "            print(\"5. Or run the cell above to auto-configure the path\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"OCR Error: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2e4d2194",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text extracted and saved to ./Tests output/output_from_text.txt\n"
     ]
    }
   ],
   "source": [
    "import pdfplumber\n",
    "\n",
    "pdf_path = \"./Tests files/test_text_only.pdf\"\n",
    "output_txt = \"./Tests output/output_from_text.txt\"\n",
    "\n",
    "with pdfplumber.open(pdf_path) as pdf:\n",
    "    full_text = \"\"\n",
    "    for page in pdf.pages:\n",
    "        full_text += page.extract_text() + \"\\n\"\n",
    "\n",
    "with open(output_txt, \"w\", encoding=\"utf-8\") as f:\n",
    "    f.write(full_text)\n",
    "\n",
    "print(f\"Text extracted and saved to {output_txt}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conceptify-ai-powered-learning-platform",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
